{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e6d29b8-4b15-4ae8-affd-0171f9969ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Auto_paint_self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df901892-3006-4ab4-a771-c34ed142daf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TBYC\\.conda\\envs\\ml\\lib\\site-packages\\xarray\\coding\\times.py:170: SerializationWarning: Ambiguous reference date string: 1-1-1 00:00:00. The first value is assumed to be the year hence will be padded with zeros to remove the ambiguity (the padded reference date string is: 0001-1-1 00:00:00). To remove this message, remove the ambiguity by padding your reference date strings with zeros.\n",
      "  warnings.warn(warning_msg, SerializationWarning)\n"
     ]
    }
   ],
   "source": [
    "CN05_PRE,lon,lat,levels,latlow,lattop,lonleft,lonright,times=Auto_paint_self.open_data_nc('one',r'E:\\CN05.1_Pre_1961_2021_daily_025x025.nc','pre','yes','time','2001-01-01','2021-12-31','yes','lon','yes','lat',18.0,53.5,73.5,135.0,0.25,0.25,'no','no',None,None,changeresolution=1,timespace=1,ifchange_west_east='no',ifinterpolate='no')\n",
    "CMO_RPH,lon,lat,levels,latlow,lattop,lonleft,lonright,times=Auto_paint_self.open_data_nc('one',r'E:\\Multi-Sources_Precipitation_NC_2001_2022\\CMORPH_China_2001_2022_2.nc','Pre','yes','time','2001-01-01','2021-12-31','yes','lon','yes','lat',18.0,53.5,73.5,135.0,0.25,0.25,'no','no',None,None,changeresolution=1,timespace=1,ifchange_west_east='no',ifinterpolate='no')\n",
    "ERA5_PRE,lon,lat,levels,latlow,lattop,lonleft,lonright,times=Auto_paint_self.open_data_nc('one',r'E:\\Multi-Sources_Precipitation_NC_2001_2022\\ERA5_China_2001_2022_2.nc','Pre','yes','time','2001-01-01','2021-12-31','yes','lon','yes','lat',18.0,53.5,73.5,135.0,0.25,0.25,'no','no',None,None,changeresolution=1,timespace=1,ifchange_west_east='no',ifinterpolate='no')\n",
    "td2m,lon,lat,levels,latlow,lattop,lonleft,lonright,times=Auto_paint_self.open_data_nc('one',r'E:\\ERA5-hourly\\mid\\2m-dewpoint-temperature-1979-2022-day.nc','d2m','yes','time','2001-01-01','2021-12-31','yes','longitude','yes','latitude',18.0,53.5,73.5,135.0,0.25,0.25,'no','no',None,None,changeresolution=1,timespace=1,ifchange_west_east='no',ifinterpolate='no')\n",
    "t2m,lon,lat,levels,latlow,lattop,lonleft,lonright,times=Auto_paint_self.open_data_nc('one',r'D:\\ERA5-hourly\\mid\\2m-temperature-1979-2022-day.nc','t2m','yes','time','2001-01-01','2021-12-31','yes','longitude','yes','latitude',18.0,53.5,73.5,135.0,0.25,0.25,'no','no',None,None,changeresolution=1,timespace=1,ifchange_west_east='no',ifinterpolate='no')\n",
    "sp,lon,lat,levels,latlow,lattop,lonleft,lonright,times=Auto_paint_self.open_data_nc('one',r'D:\\ERA5 dayly data on Single levels from 1979 to present\\single 0.25\\Surface pressure-day.nc','sp','yes','time','2001-01-01','2021-12-31','yes','longitude','yes','latitude',18.0,53.5,73.5,135.0,0.25,0.25,'no','no',None,None,changeresolution=1,timespace=1,ifchange_west_east='no',ifinterpolate='no')\n",
    "sm,lon,lat,levels,latlow,lattop,lonleft,lonright,times=Auto_paint_self.open_data_nc('one',r'D:\\ERA5 dayly data on Single levels from 1979 to present\\single 0.25\\Volumetric-soil-water-layer-1-day.nc','swvl1','yes','time','2001-01-01','2021-12-31','yes','longitude','yes','latitude',18.0,53.5,73.5,135.0,0.25,0.25,'no','no',None,None,changeresolution=1,timespace=1,ifchange_west_east='no',ifinterpolate='no')\n",
    "GPM_PRE,lon,lat,levels,latlow,lattop,lonleft,lonright,times=Auto_paint_self.open_data_nc('one',r'E:\\Multi-Sources_Precipitation_NC_2001_2022\\GPM_China_2001_2022_time.nc','precipitation','yes','time','2001-01-01','2021-12-31','yes','lon','yes','lat',18.0,53.5,73.5,135.0,0.25,0.25,'no','no',None,None,changeresolution=1,timespace=1,ifchange_west_east='no',ifinterpolate='no')\n",
    "GSMAP_PRE,lon,lat,levels,latlow,lattop,lonleft,lonright,times=Auto_paint_self.open_data_nc('one',r'E:\\Multi-Sources_Precipitation_NC_2001_2022\\GSMAP_China_2001_2022_time.nc','Pre_daily','yes','time','2001-01-01','2021-12-31','yes','lon','yes','lat',18.0,53.5,73.5,135.0,0.25,0.25,'no','no',None,None,changeresolution=1,timespace=1,ifchange_west_east='no',ifinterpolate='no')\n",
    "MSWEP_PRE,lon,lat,levels,latlow,lattop,lonleft,lonright,times=Auto_paint_self.open_data_nc('one',r'E:\\Multi-Sources_Precipitation_NC_2001_2022\\MSWEP_China_2001_2022_2.nc','Pre','yes','time','2001-01-01','2021-12-31','yes','lon','yes','lat',18.0,53.5,73.5,135.0,0.25,0.25,'no','no',None,None,changeresolution=1,timespace=1,ifchange_west_east='no',ifinterpolate='no')\n",
    "PERSIANN_CDR_PRE,lon,lat,levels,latlow,lattop,lonleft,lonright,times=Auto_paint_self.open_data_nc('one',r'E:\\Multi-Sources_Precipitation_NC_2001_2022\\PERSIANN_CDR_PRE_China_2001_2022_2.nc','Pre','yes','time','2001-01-01','2021-12-31','yes','lon','yes','lat',18.0,53.5,73.5,135.0,0.25,0.25,'no','no',None,None,changeresolution=1,timespace=1,ifchange_west_east='no',ifinterpolate='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c23628b6-2461-49b7-b50a-3a74498e85a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TBYC\\AppData\\Local\\Temp\\ipykernel_50360\\2068210167.py:21: RuntimeWarning: invalid value encountered in divide\n",
      "  vx=(vx-np.nanmean(vx,axis=0))/np.nanstd(vx,axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270912070, 10) (270912070,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vx=np.zeros((CMO_RPH.shape[0],CMO_RPH.shape[1],CMO_RPH.shape[2],10))\n",
    "vy=np.zeros((CN05_PRE.shape[0],CN05_PRE.shape[1],CN05_PRE.shape[2]),dtype='int32')\n",
    "CN05_PRE=CN05_PRE[:,::-1,:]\n",
    "CN05_PRE=np.nan_to_num(CN05_PRE,nan=0)\n",
    "vx[:,:,:,0]=CMO_RPH\n",
    "vx[:,:,:,1]=ERA5_PRE\n",
    "vx[:,:,:,2]=GPM_PRE\n",
    "vx[:,:,:,3]=GSMAP_PRE\n",
    "vx[:,:,:,4]=MSWEP_PRE\n",
    "vx[:,:,:,5]=PERSIANN_CDR_PRE\n",
    "vx[:,:,:,6]=td2m\n",
    "vx[:,:,:,7]=t2m\n",
    "vx[:,:,:,8]=sp\n",
    "vx[:,:,:,9]=sm\n",
    "vx=np.nan_to_num(vx,nan=0)\n",
    "for i in range(CN05_PRE.shape[1]):\n",
    "    for j in range(CN05_PRE.shape[2]):\n",
    "        vy[np.array(CN05_PRE[:,i,j])<0.1,i,j]=0\n",
    "        vy[np.array(CN05_PRE[:,i,j])>=0.1,i,j]=1\n",
    "vx=(vx-np.nanmean(vx,axis=0))/np.nanstd(vx,axis=0)\n",
    "vx=np.nan_to_num(vx,nan=0)\n",
    "vx=vx.reshape(vx.shape[0]*vx.shape[1]*vx.shape[2],vx.shape[3])\n",
    "vy=vy.reshape(vy.shape[0]*vy.shape[1]*vy.shape[2])\n",
    "print(vx.shape,vy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf3d43b-7509-4565-833b-565aa492e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost自动调优函数\n",
    "def Auto_xgboost(vy,vx,test_size = 0.25,task_mode='regression',if_best_mode='no',modelpath=None,ifcross_validation='no',k_fold_num=5,default_learning_rate=0.5,default_max_depth=50,default_num_leaves=100,default_max_bin=256,boosting_type='dart',n_estimators=10000,metrics='default',subsample=0.7,ifmute='no',ifweight='yes',ifrandom_split='yes',ifsave='no',savepath=None,device='cpu'):\n",
    "    from xgboost import XGBRegressor,XGBClassifier\n",
    "    import numpy as np\n",
    "    import math\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from scipy.stats import pearsonr\n",
    "    from sklearn.inspection import permutation_importance\n",
    "    from sklearn.model_selection import cross_validate\n",
    "    from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,mean_squared_error\n",
    "    import warnings\n",
    "    import joblib\n",
    "    import shap\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    weights=None\n",
    "    if ifrandom_split=='yes':\n",
    "        trainy,testy,trainx,testx = train_test_split(vy,vx,test_size=test_size,random_state=25)\n",
    "    else:\n",
    "        index=int((1-test_size)*vy.shape[0])\n",
    "        trainy=vy[:index]\n",
    "        testy=vy[index:]\n",
    "        trainx=vx[:index,:]\n",
    "        testx=vx[index:,:]\n",
    "    if if_best_mode =='no':\n",
    "        learning_rate = np.zeros((3))\n",
    "        learning_rate[1] = default_learning_rate\n",
    "        if math.floor(default_learning_rate) > 1:\n",
    "            learning_rate[0] = default_learning_rate+1\n",
    "            learning_rate[2] = default_learning_rate-1\n",
    "        elif math.floor(default_learning_rate*10) > 1:\n",
    "            learning_rate[0] = default_learning_rate+0.1\n",
    "            learning_rate[2] = default_learning_rate-0.1\n",
    "        elif math.floor(default_learning_rate*100) > 1:\n",
    "            learning_rate[0] = default_learning_rate+0.01\n",
    "            learning_rate[2] = default_learning_rate-0.01\n",
    "        elif math.floor(default_learning_rate*1000) > 1:\n",
    "            learning_rate[0] = default_learning_rate+0.001\n",
    "            learning_rate[2] = default_learning_rate-0.001\n",
    "        else:\n",
    "            print('默认学习率过小')\n",
    "        max_depth = np.array([0,0,0])\n",
    "        max_depth[1] = int(default_max_depth)\n",
    "        if default_max_depth > 10:\n",
    "            max_depth[0] = int(default_max_depth-5)\n",
    "            max_depth[2] = int(default_max_depth+5)\n",
    "        elif default_max_depth > 2:\n",
    "            max_depth[0] = int(default_max_depth-2)\n",
    "            max_depth[2] = int(default_max_depth+2)\n",
    "        elif default_max_depth >= 1:\n",
    "            max_depth[0] = int(default_max_depth)\n",
    "            max_depth[2] = int(default_max_depth+2)\n",
    "        else:\n",
    "            print('默认最大树深度过小')\n",
    "        num_leaves = np.array([0,0,0])\n",
    "        num_leaves[1] = int(default_num_leaves)\n",
    "        if default_num_leaves >20 :\n",
    "            num_leaves[0] = int(default_num_leaves-10)\n",
    "            num_leaves[2] = int(default_num_leaves+10)\n",
    "        elif default_num_leaves >2 :\n",
    "            num_leaves[0] = int(default_num_leaves-2)\n",
    "            num_leaves[2] = int(default_num_leaves+2)\n",
    "        elif default_num_leaves >= 1 :\n",
    "            num_leaves[0] = int(default_num_leaves)\n",
    "            num_leaves[2] = int(default_num_leaves+2)\n",
    "        else:\n",
    "             print('默认最大叶子节点数过小')\n",
    "        max_bin = np.array([0,0,0])\n",
    "        max_bin[1]=int(default_max_bin)\n",
    "        if default_max_bin > 100:\n",
    "            max_bin[0]=int(default_max_bin-20)\n",
    "            max_bin[2]=int(default_max_bin+20)\n",
    "        elif default_max_bin > 50:\n",
    "            max_bin[0]=int(default_max_bin-10)\n",
    "            max_bin[2]=int(default_max_bin+10)\n",
    "        elif default_max_bin > 10:\n",
    "            max_bin[0]=int(default_max_bin-5)\n",
    "            max_bin[2]=int(default_max_bin+5)\n",
    "        elif default_max_bin >2:\n",
    "            max_bin[0]=int(default_max_bin-2)\n",
    "            max_bin[2]=int(default_max_bin+2)\n",
    "        elif default_max_bin >=1:\n",
    "            max_bin[0]=int(default_max_bin)\n",
    "            max_bin[2]=int(default_max_bin+2)\n",
    "        else:\n",
    "            print('默认最大离散条柱数过小')\n",
    "        round_num = 0\n",
    "        best_learning_rate = default_learning_rate\n",
    "        best_max_depth = default_max_depth\n",
    "        best_num_leaves = default_num_leaves\n",
    "        best_max_bin = default_max_bin\n",
    "        while(1):\n",
    "            round_num = round_num+1\n",
    "            best_num = 0\n",
    "            learning_rate_best = []\n",
    "            max_depth_best = []\n",
    "            num_leaves_best = []\n",
    "            max_bin_best = []\n",
    "            r = np.zeros((3,3,3,3))\n",
    "            p = np.zeros((3,3,3,3))\n",
    "            rmax = 0\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    for k in range(3):\n",
    "                        for l in range(3):\n",
    "                            if ifcross_validation=='yes':\n",
    "                                model = 0 \n",
    "                                if device=='gpu':\n",
    "                                    if task_mode=='regression':\n",
    "                                        model = XGBRegressor(booster=boosting_type,n_estimators=n_estimators,learning_rate=learning_rate[i],max_depth=max_depth[j],subsample=subsample,max_leaves=num_leaves[k],max_bin=max_bin[l],random_state=325,verbosity=0,tree_method='hist',device=\"cuda\" )\n",
    "                                    elif task_mode=='binary_classify':\n",
    "                                        model = XGBClassifier(booster=boosting_type,n_estimators=n_estimators,learning_rate=learning_rate[i],max_depth=max_depth[j],subsample=subsample,max_leaves=num_leaves[k],max_bin=max_bin[l],random_state=325,verbosity=0,tree_method='hist',device=\"cuda\" )\n",
    "                                    elif task_mode=='multi_classify':\n",
    "                                        model = XGBClassifier(booster=boosting_type,n_estimators=n_estimators,learning_rate=learning_rate[i],max_depth=max_depth[j],subsample=subsample,max_leaves=num_leaves[k],max_bin=max_bin[l],random_state=325,verbosity=0,tree_method='hist',device=\"cuda\" )\n",
    "                                else:\n",
    "                                    if task_mode=='regression':\n",
    "                                        model = XGBRegressor(booster=boosting_type,n_estimators=n_estimators,learning_rate=learning_rate[i],max_depth=max_depth[j],subsample=subsample,max_leaves=num_leaves[k],max_bin=max_bin[l],random_state=325,verbosity=0 )\n",
    "                                    elif task_mode=='binary_classify':\n",
    "                                        model = XGBClassifier(booster=boosting_type,n_estimators=n_estimators,learning_rate=learning_rate[i],max_depth=max_depth[j],subsample=subsample,max_leaves=num_leaves[k],max_bin=max_bin[l],random_state=325,verbosity=0 )\n",
    "                                    elif task_mode=='multi_classify':\n",
    "                                        model = XGBClassifier(booster=boosting_type,n_estimators=n_estimators,learning_rate=learning_rate[i],max_depth=max_depth[j],subsample=subsample,max_leaves=num_leaves[k],max_bin=max_bin[l],random_state=325,verbosity=0 )\n",
    "                                if task_mode=='regression':\n",
    "                                    result=cross_validate(model,trainx,trainy,scoring='r2',cv=k_fold_num,return_train_score=True,return_estimator=True)\n",
    "                                    r[i,j,k,l]=np.nanmean(np.sqrt(np.array(result['test_score'])))\n",
    "                                elif task_mode=='binary_classify':\n",
    "                                    if metrics=='f1':\n",
    "                                        result=cross_validate(model,trainx,trainy,scoring='f1',cv=k_fold_num,return_train_score=True,return_estimator=True)\n",
    "                                    elif metrics=='accuracy':\n",
    "                                        result=cross_validate(model,trainx,trainy,scoring='accuracy',cv=k_fold_num,return_train_score=True,return_estimator=True)\n",
    "                                    elif metrics=='recall':\n",
    "                                        result=cross_validate(model,trainx,trainy,scoring='recall',cv=k_fold_num,return_train_score=True,return_estimator=True)\n",
    "                                    elif metrics=='precision':\n",
    "                                        result=cross_validate(model,trainx,trainy,scoring='precision',cv=k_fold_num,return_train_score=True,return_estimator=True)\n",
    "                                    r[i,j,k,l]=np.nanmean(np.sqrt(np.array(result['test_score'])))\n",
    "                                elif task_mode=='multi_classify':\n",
    "                                    result=cross_validate(model,trainx,trainy,scoring='accuracy',cv=k_fold_num,return_train_score=True,return_estimator=True)\n",
    "                                    r[i,j,k,l]=np.nanmean(np.sqrt(np.array(result['test_score'])))\n",
    "                            else:\n",
    "                                model = 0 \n",
    "                                if device=='gpu':\n",
    "                                    if task_mode=='regression':\n",
    "                                        model = XGBRegressor(booster=boosting_type,n_estimators=n_estimators,learning_rate=learning_rate[i],max_depth=max_depth[j],subsample=subsample,max_leaves=num_leaves[k],max_bin=max_bin[l],random_state=325,verbosity=0,tree_method='hist',device=\"cuda\" )\n",
    "                                    elif task_mode=='binary_classify':\n",
    "                                        model = XGBClassifier(booster=boosting_type,n_estimators=n_estimators,learning_rate=learning_rate[i],max_depth=max_depth[j],subsample=subsample,max_leaves=num_leaves[k],max_bin=max_bin[l],random_state=325,verbosity=0,tree_method='hist',device=\"cuda\" )\n",
    "                                    elif task_mode=='multi_classify':\n",
    "                                        model = XGBClassifier(booster=boosting_type,n_estimators=n_estimators,learning_rate=learning_rate[i],max_depth=max_depth[j],subsample=subsample,max_leaves=num_leaves[k],max_bin=max_bin[l],random_state=325,verbosity=0,tree_method='hist',device=\"cuda\" )\n",
    "                                else:\n",
    "                                    if task_mode=='regression':\n",
    "                                        model = XGBRegressor(booster=boosting_type,n_estimators=n_estimators,learning_rate=learning_rate[i],max_depth=max_depth[j],subsample=subsample,max_leaves=num_leaves[k],max_bin=max_bin[l],random_state=325,verbosity=0 )\n",
    "                                    elif task_mode=='binary_classify':\n",
    "                                        model = XGBClassifier(booster=boosting_type,n_estimators=n_estimators,learning_rate=learning_rate[i],max_depth=max_depth[j],subsample=subsample,max_leaves=num_leaves[k],max_bin=max_bin[l],random_state=325,verbosity=0 )\n",
    "                                    elif task_mode=='multi_classify':\n",
    "                                        model = XGBClassifier(booster=boosting_type,n_estimators=n_estimators,learning_rate=learning_rate[i],max_depth=max_depth[j],subsample=subsample,max_leaves=num_leaves[k],max_bin=max_bin[l],random_state=325,verbosity=0 )\n",
    "                                model.fit(trainx,trainy,eval_set=[(testx,testy),(trainx,trainy)],verbose=0)\n",
    "                                predicty = model.predict(testx)\n",
    "                                if task_mode=='regression':\n",
    "                                    if metrics=='pearson' or metrics=='default':\n",
    "                                        r[i,j,k,l],p[i,j,k,l]=pearsonr(predicty,testy)\n",
    "                                    elif metrics=='mse':\n",
    "                                        r[i,j,k,l]=1.0/mean_squared_error(testy, predicty)\n",
    "                                        p=0\n",
    "                                elif task_mode=='binary_classify':\n",
    "                                    if metrics=='f1' or metrics=='default':\n",
    "                                        r[i,j,k,l]=f1_score(testy, predicty)\n",
    "                                    elif metrics=='accuracy':\n",
    "                                        r[i,j,k,l]=accuracy_score(testy, predicty)\n",
    "                                    elif metrics=='recall':\n",
    "                                        r[i,j,k,l]=recall_score(testy, predicty)\n",
    "                                    elif metrics=='precision':\n",
    "                                        r[i,j,k,l]=precision_score(testy, predicty)\n",
    "                                    p=0\n",
    "                                elif task_mode=='multi_classify':\n",
    "                                    if metrics=='accuracy' or metrics=='default':\n",
    "                                        r[i,j,k,l]=accuracy_score(testy, predicty)\n",
    "                                        p=0\n",
    "            rmax = np.nanmax(r)\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    for k in range(3):\n",
    "                        for l in range(3):\n",
    "                            if r[i,j,k,l] == rmax:\n",
    "                                learning_rate_best.append(i)\n",
    "                                max_depth_best.append(j)\n",
    "                                num_leaves_best.append(k)\n",
    "                                max_bin_best.append(l)\n",
    "            if not(1 in learning_rate_best):\n",
    "                if 2 in learning_rate_best:\n",
    "                    best_learning_rate = learning_rate[2]\n",
    "                elif 0 in learning_rate_best:\n",
    "                    best_learning_rate = learning_rate[0]\n",
    "                learning_rate[1] = best_learning_rate\n",
    "                if math.floor(best_learning_rate) > 1:\n",
    "                    learning_rate[0] = best_learning_rate+1\n",
    "                    learning_rate[2] = best_learning_rate-1\n",
    "                elif math.floor(best_learning_rate*10) > 1:\n",
    "                    learning_rate[0] = best_learning_rate+0.1\n",
    "                    learning_rate[2] = best_learning_rate-0.1\n",
    "                elif math.floor(best_learning_rate*100) > 1:\n",
    "                    learning_rate[0] = best_learning_rate+0.01\n",
    "                    learning_rate[2] = best_learning_rate-0.01\n",
    "                elif math.floor(best_learning_rate*1000) > 1:\n",
    "                    learning_rate[0] = best_learning_rate+0.001\n",
    "                    learning_rate[2] = best_learning_rate-0.001\n",
    "                else:\n",
    "                    print('调参学习率过小')\n",
    "                    break\n",
    "            elif (1 in learning_rate_best) and (2 in learning_rate_best) and (not(0 in learning_rate_best)):\n",
    "                best_learning_rate = (learning_rate[2]+learning_rate[1])/2\n",
    "                learning_rate[1] = best_learning_rate\n",
    "                if math.floor(best_learning_rate) > 1:\n",
    "                    learning_rate[0] = best_learning_rate+1\n",
    "                    learning_rate[2] = best_learning_rate-1\n",
    "                elif math.floor(best_learning_rate*10) > 1:\n",
    "                    learning_rate[0] = best_learning_rate+0.1\n",
    "                    learning_rate[2] = best_learning_rate-0.1\n",
    "                elif math.floor(best_learning_rate*100) > 1:\n",
    "                    learning_rate[0] = best_learning_rate+0.01\n",
    "                    learning_rate[2] = best_learning_rate-0.01\n",
    "                elif math.floor(best_learning_rate*1000) > 1:\n",
    "                    learning_rate[0] = best_learning_rate+0.001\n",
    "                    learning_rate[2] = best_learning_rate-0.001\n",
    "                else:\n",
    "                    print('调参学习率过小')\n",
    "                    break\n",
    "            elif (1 in learning_rate_best) and (0 in learning_rate_best) and (not(2 in learning_rate_best)):\n",
    "                best_learning_rate = (learning_rate[0]+learning_rate[1])/2\n",
    "                learning_rate[1] = best_learning_rate\n",
    "                if math.floor(best_learning_rate) > 1:\n",
    "                    learning_rate[0] = best_learning_rate+1\n",
    "                    learning_rate[2] = best_learning_rate-1\n",
    "                elif math.floor(best_learning_rate*10) > 1:\n",
    "                    learning_rate[0] = best_learning_rate+0.1\n",
    "                    learning_rate[2] = best_learning_rate-0.1\n",
    "                elif math.floor(best_learning_rate*100) > 1:\n",
    "                    learning_rate[0] = best_learning_rate+0.01\n",
    "                    learning_rate[2] = best_learning_rate-0.01\n",
    "                elif math.floor(best_learning_rate*1000) > 1:\n",
    "                    learning_rate[0] = best_learning_rate+0.001\n",
    "                    learning_rate[2] = best_learning_rate-0.001\n",
    "                else:\n",
    "                    print('调参学习率过小')\n",
    "                    break\n",
    "            else:\n",
    "                best_num = best_num+1\n",
    "            if not(1 in max_depth_best):\n",
    "                if 2 in max_depth_best:\n",
    "                    best_max_depth = max_depth[2]\n",
    "                elif 0 in max_depth_best:\n",
    "                    best_max_depth = max_depth[0]\n",
    "                max_depth[1] = best_max_depth\n",
    "                if best_max_depth > 15:\n",
    "                    max_depth[0] = int(best_max_depth-5)\n",
    "                    max_depth[2] = int(best_max_depth+5)\n",
    "                elif best_max_depth >= 3:\n",
    "                    max_depth[0] = int(best_max_depth-2)\n",
    "                    max_depth[2] = int(best_max_depth+2)\n",
    "                else:\n",
    "                    max_depth[0] = int(best_max_depth)\n",
    "                    max_depth[2] = int(best_max_depth+2)\n",
    "                    best_num = best_num+1\n",
    "            elif (1 in max_depth_best) and (2 in max_depth_best) and (not(0 in max_depth_best)):\n",
    "                best_max_depth = int((max_depth[2]+max_depth[1])/2)\n",
    "                max_depth[1] = best_max_depth\n",
    "                if best_max_depth > 15:\n",
    "                    max_depth[0] = int(best_max_depth-5)\n",
    "                    max_depth[2] = int(best_max_depth+5)\n",
    "                elif best_max_depth >= 3:\n",
    "                    max_depth[0] = int(best_max_depth-2)\n",
    "                    max_depth[2] = int(best_max_depth+2)\n",
    "                else:\n",
    "                    max_depth[0] = int(best_max_depth)\n",
    "                    max_depth[2] = int(best_max_depth+2)\n",
    "                    best_num = best_num+1\n",
    "            elif (1 in max_depth_best) and (0 in max_depth_best) and (not(2 in max_depth_best)):\n",
    "                best_max_depth = int((max_depth[0]+max_depth[1])/2)\n",
    "                max_depth[1] = best_max_depth\n",
    "                if best_max_depth > 15:\n",
    "                    max_depth[0] = int(best_max_depth-5)\n",
    "                    max_depth[2] = int(best_max_depth+5)\n",
    "                elif best_max_depth >= 3:\n",
    "                    max_depth[0] = int(best_max_depth-2)\n",
    "                    max_depth[2] = int(best_max_depth+2)\n",
    "                else:\n",
    "                    max_depth[0] = int(best_max_depth)\n",
    "                    max_depth[2] = int(best_max_depth+2)\n",
    "                    best_num = best_num+1\n",
    "            else:\n",
    "                best_num = best_num+1\n",
    "            if not(1 in num_leaves_best):\n",
    "                if 2 in num_leaves_best:\n",
    "                    best_num_leaves = num_leaves[2]\n",
    "                elif 0 in num_leaves_best:\n",
    "                    best_num_leaves = num_leaves[0]\n",
    "                num_leaves[1] = best_num_leaves\n",
    "                if best_num_leaves >30 :\n",
    "                    num_leaves[0] = int(best_num_leaves-10)\n",
    "                    num_leaves[2] = int(best_num_leaves+10)\n",
    "                elif best_num_leaves >10:\n",
    "                    num_leaves[0] = int(best_num_leaves-4)\n",
    "                    num_leaves[2] = int(best_num_leaves+4)\n",
    "                elif best_num_leaves >=3:\n",
    "                    num_leaves[0] = int(best_num_leaves-2)\n",
    "                    num_leaves[2] = int(best_num_leaves+2)\n",
    "                else:\n",
    "                    num_leaves[0] = int(best_num_leaves)\n",
    "                    num_leaves[2] = int(best_num_leaves+2)\n",
    "                    best_num = best_num+1\n",
    "            elif (1 in num_leaves_best) and (2 in num_leaves_best) and (not(0 in num_leaves_best)):\n",
    "                best_num_leaves = int((num_leaves[2]+num_leaves[1])/2)\n",
    "                num_leaves[1] = best_num_leaves\n",
    "                if best_num_leaves >30 :\n",
    "                    num_leaves[0] = int(best_num_leaves-10)\n",
    "                    num_leaves[2] = int(best_num_leaves+10)\n",
    "                elif best_num_leaves >10:\n",
    "                    num_leaves[0] = int(best_num_leaves-4)\n",
    "                    num_leaves[2] = int(best_num_leaves+4)\n",
    "                elif best_num_leaves >=3:\n",
    "                    num_leaves[0] = int(best_num_leaves-2)\n",
    "                    num_leaves[2] = int(best_num_leaves+2)\n",
    "                else:\n",
    "                    num_leaves[0] = int(best_num_leaves)\n",
    "                    num_leaves[2] = int(best_num_leaves+2)\n",
    "                    best_num = best_num+1\n",
    "            elif (1 in num_leaves_best) and (0 in num_leaves_best) and (not(2 in num_leaves_best)):\n",
    "                best_num_leaves = int((num_leaves[0]+num_leaves[1])/2)\n",
    "                num_leaves[1] = best_num_leaves\n",
    "                if best_num_leaves >30 :\n",
    "                    num_leaves[0] = int(best_num_leaves-10)\n",
    "                    num_leaves[2] = int(best_num_leaves+10)\n",
    "                elif best_num_leaves >10:\n",
    "                    num_leaves[0] = int(best_num_leaves-4)\n",
    "                    num_leaves[2] = int(best_num_leaves+4)\n",
    "                elif best_num_leaves >=3:\n",
    "                    num_leaves[0] = int(best_num_leaves-2)\n",
    "                    num_leaves[2] = int(best_num_leaves+2)\n",
    "                else:\n",
    "                    num_leaves[0] = int(best_num_leaves)\n",
    "                    num_leaves[2] = int(best_num_leaves+2)\n",
    "                    best_num = best_num+1\n",
    "            else:\n",
    "                best_num = best_num+1\n",
    "            if not(1 in max_bin_best):\n",
    "                if 2 in max_bin_best:\n",
    "                    best_max_bin = max_bin[2]\n",
    "                elif 0 in max_bin_best:\n",
    "                    best_max_bin = max_bin[0]\n",
    "                max_bin[1] = best_max_bin\n",
    "                if best_max_bin > 100:\n",
    "                    max_bin[0]=int(best_max_bin-20)\n",
    "                    max_bin[2]=int(best_max_bin+20)\n",
    "                elif best_max_bin > 50:\n",
    "                    max_bin[0]=int(best_max_bin-10)\n",
    "                    max_bin[2]=int(best_max_bin+10)\n",
    "                elif best_max_bin > 10:\n",
    "                    max_bin[0]=int(best_max_bin-5)\n",
    "                    max_bin[2]=int(best_max_bin+5)\n",
    "                elif best_max_bin >= 3:\n",
    "                    max_bin[0]=int(best_max_bin-2)\n",
    "                    max_bin[2]=int(best_max_bin+2)\n",
    "                else:\n",
    "                    max_bin[0]=int(best_max_bin)\n",
    "                    max_bin[2]=int(best_max_bin+2)\n",
    "                    best_num = best_num+1\n",
    "            elif (1 in max_bin_best) and (2 in max_bin_best) and (not(0 in max_bin_best)):\n",
    "                best_max_bin = int((max_bin[2]+max_bin[1])/2)\n",
    "                max_bin[1] = best_max_bin\n",
    "                if best_max_bin > 100:\n",
    "                    max_bin[0]=int(best_max_bin-20)\n",
    "                    max_bin[2]=int(best_max_bin+20)\n",
    "                elif best_max_bin > 50:\n",
    "                    max_bin[0]=int(best_max_bin-10)\n",
    "                    max_bin[2]=int(best_max_bin+10)\n",
    "                elif best_max_bin > 10:\n",
    "                    max_bin[0]=int(best_max_bin-5)\n",
    "                    max_bin[2]=int(best_max_bin+5)\n",
    "                elif best_max_bin >= 3:\n",
    "                    max_bin[0]=int(best_max_bin-2)\n",
    "                    max_bin[2]=int(best_max_bin+2)\n",
    "                else:\n",
    "                    max_bin[0]=int(best_max_bin)\n",
    "                    max_bin[2]=int(best_max_bin+2)\n",
    "                    best_num = best_num+1\n",
    "            elif (1 in max_bin_best) and (0 in max_bin_best) and (not(2 in max_bin_best)):\n",
    "                best_max_bin = int((max_bin[0]+max_bin[1])/2)\n",
    "                max_bin[1] = best_max_bin\n",
    "                if best_max_bin > 100:\n",
    "                    max_bin[0]=int(best_max_bin-20)\n",
    "                    max_bin[2]=int(best_max_bin+20)\n",
    "                elif best_max_bin > 50:\n",
    "                    max_bin[0]=int(best_max_bin-10)\n",
    "                    max_bin[2]=int(best_max_bin+10)\n",
    "                elif best_max_bin > 10:\n",
    "                    max_bin[0]=int(best_max_bin-5)\n",
    "                    max_bin[2]=int(best_max_bin+5)\n",
    "                elif best_max_bin >= 3:\n",
    "                    max_bin[0]=int(best_max_bin-2)\n",
    "                    max_bin[2]=int(best_max_bin+2)\n",
    "                else:\n",
    "                    max_bin[0]=int(best_max_bin)\n",
    "                    max_bin[2]=int(best_max_bin+2)\n",
    "                    best_num = best_num+1\n",
    "            else:\n",
    "                best_num = best_num+1\n",
    "            if ifmute == 'no':\n",
    "                print('目前是第',round_num,'次调优')\n",
    "                if task_mode=='regression':\n",
    "                    if metrics=='pearson' or metrics=='default':\n",
    "                        print('目前最好结果（相关系数）',rmax)\n",
    "                    elif metrics=='mse':\n",
    "                        print('目前最好结果（均方根误差）',1.0/rmax)\n",
    "                elif task_mode=='binary_classify':\n",
    "                    if metrics=='f1' or metrics=='default':\n",
    "                        print('目前最好结果（召回率+精确率）',rmax,'召回率',recall_score(testy, predicty),'精确率',precision_score(testy, predicty),'准确率',accuracy_score(testy, predicty))\n",
    "                    elif metrics=='accuracy':\n",
    "                        print('目前最好结果（准确率）',rmax,'召回率',recall_score(testy, predicty),'精确率',precision_score(testy, predicty))\n",
    "                    elif metrics=='recall':\n",
    "                        print('目前最好结果（召回率）',rmax,'精确率',precision_score(testy, predicty),'准确率',accuracy_score(testy, predicty))\n",
    "                    elif metrics=='precision':\n",
    "                        print('目前最好结果（精确率）',rmax,'召回率',recall_score(testy, predicty),'准确率',accuracy_score(testy, predicty))\n",
    "                elif task_mode=='multi_classify':\n",
    "                    if metrics=='accuracy' or metrics=='default':\n",
    "                        print('目前最好结果（准确率）',rmax)\n",
    "                print('目前最优学习率',best_learning_rate,'目前最优最大树深度',best_max_depth,'目前最优最大叶子节点数',best_num_leaves,'最优最大离散条柱数',best_max_bin)\n",
    "            if best_num ==4:\n",
    "                print('已找到最优参数：')\n",
    "                print('最优学习率：',best_learning_rate)\n",
    "                print('最优最大树深度:',best_max_depth)\n",
    "                print('最优最大叶子节点数',best_num_leaves)\n",
    "                print('最优最大离散条柱数：',best_max_bin)\n",
    "                model = 0 \n",
    "                if device=='gpu':\n",
    "                    if task_mode=='regression':\n",
    "                        model = XGBRegressor(booster=boosting_type,n_estimators=n_estimators,learning_rate=best_learning_rate,max_depth=best_max_depth,subsample=subsample,max_leaves=best_num_leaves,max_bin=best_max_bin,random_state=325,verbosity=0,tree_method='hist',device=\"cuda\" )\n",
    "                    elif task_mode=='binary_classify':\n",
    "                        model = XGBClassifier(booster=boosting_type,n_estimators=n_estimators,learning_rate=best_learning_rate,max_depth=best_max_depth,subsample=subsample,max_leaves=best_num_leaves,max_bin=best_max_bin,random_state=325,verbosity=0,tree_method='hist',device=\"cuda\" )\n",
    "                    elif task_mode=='multi_classify':\n",
    "                        model = XGBClassifier(booster=boosting_type,n_estimators=n_estimators,learning_rate=best_learning_rate,max_depth=best_max_depth,subsample=subsample,max_leaves=best_num_leaves,max_bin=best_max_bin,random_state=325,verbosity=0,tree_method='hist',device=\"cuda\" )\n",
    "                else:\n",
    "                    if task_mode=='regression':\n",
    "                        model = XGBRegressor(booster=boosting_type,n_estimators=n_estimators,learning_rate=best_learning_rate,max_depth=best_max_depth,subsample=subsample,max_leaves=best_num_leaves,max_bin=best_max_bin,random_state=325,verbosity=0 )\n",
    "                    elif task_mode=='binary_classify':\n",
    "                        model = XGBClassifier(booster=boosting_type,n_estimators=n_estimators,learning_rate=best_learning_rate,max_depth=best_max_depth,subsample=subsample,max_leaves=best_num_leaves,max_bin=best_max_bin,random_state=325,verbosity=0 )\n",
    "                    elif task_mode=='multi_classify':\n",
    "                        model = XGBClassifier(booster=boosting_type,n_estimators=n_estimators,learning_rate=best_learning_rate,max_depth=best_max_depth,subsample=subsample,max_leaves=best_num_leaves,max_bin=best_max_bin,random_state=325,verbosity=0 )\n",
    "                clf=model.fit(trainx,trainy,eval_set=[(testx,testy),(trainx,trainy)],verbose=0)\n",
    "                predicty = model.predict(testx)\n",
    "                if task_mode=='regression':\n",
    "                    if metrics=='default' or metrics=='pearson':\n",
    "                        r,p = pearsonr(predicty,testy)\n",
    "                    elif metrics=='mse':\n",
    "                        r = 1.0/mean_squared_error(testy, predicty)\n",
    "                        p=0\n",
    "                elif task_mode=='binary_classify':\n",
    "                    if metrics=='default' or metrics=='f1' :\n",
    "                        r=f1_score(testy, predicty)\n",
    "                    elif metrics=='accuracy':\n",
    "                        r=accuracy_score(testy, predicty)\n",
    "                    elif metrics=='recall':\n",
    "                        r=recall_score(testy, predicty)\n",
    "                    elif metrics=='precision':\n",
    "                        r=precision_score(testy, predicty)\n",
    "                    p=0\n",
    "                elif task_mode=='multi_classify':\n",
    "                    if metrics=='default' or metrics=='accuracy':\n",
    "                        r=accuracy_score(testy, predicty)\n",
    "                        p=0\n",
    "                if ifweight=='yes' or ifweight=='shap':\n",
    "                    weights=np.zeros((testx.shape[1]))\n",
    "                    if testx.shape[0]>=100:\n",
    "                        index=np.random.randint(0,testx.shape[0],size=100)\n",
    "                        explainer = shap.TreeExplainer(model,testx[index,:])\n",
    "                        weights_more = np.abs(explainer.shap_values(testx[index,:]))\n",
    "                    else:\n",
    "                        explainer = shap.TreeExplainer(model,testx)\n",
    "                        weights_more = np.abs(explainer.shap_values(testx))\n",
    "                    weight=np.nanmean(weights_more,axis=(0))\n",
    "                    for i in range(testx.shape[1]):\n",
    "                        weights[i]=(weight[i]/np.nansum(weight))*100\n",
    "                        print('预报因子',i+1,'的贡献：',np.array(weights[i]),'％')\n",
    "                elif ifweight=='PI':\n",
    "                    weights=[]\n",
    "                    weight_more=[]\n",
    "                    result=permutation_importance(clf,trainx,trainy,n_repeats=10,random_state=325)\n",
    "                    weight=result.importances_mean\n",
    "                    for i in range(len(weight)):\n",
    "                        weight_more.append(weight[i])\n",
    "                    weight_more=np.array(weight_more)\n",
    "                    for i in range(len(weight)):\n",
    "                        weights.append(((weight[i]/np.nansum(weight_more,axis=0))*100))\n",
    "                        print('预报因子',i+1,'的贡献：',np.array(weights[i]),'％')\n",
    "                if ifsave=='yes':\n",
    "                    joblib.dump(clf,savepath)\n",
    "                break\n",
    "    else:\n",
    "        r=0\n",
    "        p=0\n",
    "        if if_best_mode=='yes':\n",
    "            if device=='gpu':\n",
    "                if task_mode=='regression':\n",
    "                    model = XGBRegressor(booster=boosting_type,n_estimators=n_estimators,learning_rate=default_learning_rate,max_depth=default_max_depth,subsample=subsample,num_leaves=default_num_leaves,max_bin=default_max_bin,random_state=325,verbosity=0,tree_method='hist',device=\"cuda\" )\n",
    "                elif task_mode=='binary_classify':\n",
    "                    model = XGBClassifier(booster=boosting_type,n_estimators=n_estimators,learning_rate=default_learning_rate,max_depth=default_max_depth,subsample=subsample,num_leaves=default_num_leaves,max_bin=default_max_bin,random_state=325,verbosity=0,tree_method='hist',device=\"cuda\" )\n",
    "                elif task_mode=='multi_classify':\n",
    "                    model = XGBClassifier(booster=boosting_type,n_estimators=n_estimators,learning_rate=default_learning_rate,max_depth=default_max_depth,subsample=subsample,num_leaves=default_num_leaves,max_bin=default_max_bin,random_state=325,verbosity=0,tree_method='hist',device=\"cuda\" )\n",
    "            else:\n",
    "                if task_mode=='regression':\n",
    "                    model = XGBRegressor(booster=boosting_type,n_estimators=n_estimators,learning_rate=default_learning_rate,max_depth=default_max_depth,subsample=subsample,num_leaves=default_num_leaves,max_bin=default_max_bin,random_state=325,verbosity=0 )\n",
    "                elif task_mode=='binary_classify':\n",
    "                    model = XGBClassifier(booster=boosting_type,n_estimators=n_estimators,learning_rate=default_learning_rate,max_depth=default_max_depth,subsample=subsample,num_leaves=default_num_leaves,max_bin=default_max_bin,random_state=325,verbosity=0 )\n",
    "                elif task_mode=='multi_classify':\n",
    "                    model = XGBClassifier(booster=boosting_type,n_estimators=n_estimators,learning_rate=default_learning_rate,max_depth=default_max_depth,subsample=subsample,num_leaves=default_num_leaves,max_bin=default_max_bin,random_state=325,verbosity=0 )\n",
    "        elif if_best_mode=='load':\n",
    "            model=joblib.load(modelpath)\n",
    "        if n_estimators!=0:\n",
    "            clf=model.fit(trainx,trainy,eval_set=[(testx,testy),(trainx,trainy)],verbose=0)\n",
    "        predicty = model.predict(testx)\n",
    "        if task_mode=='regression':\n",
    "            if metrics=='default' or metrics=='pearson':\n",
    "                r,p = pearsonr(predicty,testy)\n",
    "            elif metrics=='mse':\n",
    "                r = 1.0/mean_squared_error(testy, predicty)\n",
    "                p=0\n",
    "        elif task_mode=='binary_classify':\n",
    "            if metrics=='default' or metrics=='f1' :\n",
    "                r=f1_score(testy, predicty)\n",
    "            elif metrics=='accuracy':\n",
    "                r=accuracy_score(testy, predicty)\n",
    "            elif metrics=='recall':\n",
    "                r=recall_score(testy, predicty)\n",
    "            elif metrics=='precision':\n",
    "                r=precision_score(testy, predicty)\n",
    "            p=0\n",
    "        elif task_mode=='multi_classify':\n",
    "            if metrics=='default' or metrics=='accuracy':\n",
    "                r=accuracy_score(testy, predicty)\n",
    "                p=0\n",
    "        if ifweight=='yes' or ifweight=='shap':\n",
    "            weights=np.zeros((testx.shape[1]))\n",
    "            if testx.shape[0]>=100:\n",
    "                index=np.random.randint(0,testx.shape[0],size=100)\n",
    "                explainer = shap.TreeExplainer(model,testx[index,:])\n",
    "                weights_more = np.abs(explainer.shap_values(testx[index,:]))\n",
    "            else:\n",
    "                explainer = shap.TreeExplainer(model,testx)\n",
    "                weights_more = np.abs(explainer.shap_values(testx))\n",
    "            weight=np.nanmean(weights_more,axis=(0))\n",
    "            for i in range(testx.shape[1]):\n",
    "                weights[i]=(weight[i]/np.nansum(weight))*100\n",
    "                print('预报因子',i+1,'的贡献：',np.array(weights[i]),'％')\n",
    "        elif ifweight=='PI':\n",
    "            weights=[]\n",
    "            weight_more=[]\n",
    "            result=permutation_importance(clf,trainx,trainy,n_repeats=10,random_state=325)\n",
    "            weight=result.importances_mean\n",
    "            for i in range(len(weight)):\n",
    "                weight_more.append(weight[i])\n",
    "            weight_more=np.array(weight_more)\n",
    "            for i in range(len(weight)):\n",
    "                weights.append(((weight[i]/np.nansum(weight_more,axis=0))*100))\n",
    "                print('预报因子',i+1,'的贡献：',np.array(weights[i]),'％')\n",
    "        if ifsave=='yes':\n",
    "            if n_estimators!=0:\n",
    "                joblib.dump(clf,savepath)\n",
    "            else:\n",
    "                joblib.dump(model,savepath)\n",
    "    return model,predicty,testy,r,p,weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edebd4c-d84b-4069-a821-3515a6d90d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model,predicty,testy,r,p,weights=Auto_xgboost(vy,vx,test_size = 0.2,task_mode='binary_classify',if_best_mode='no',modelpath=None,ifcross_validation='no',k_fold_num=5,default_learning_rate=0.1,default_max_depth=50,default_num_leaves=100,default_max_bin=256,boosting_type='dart',n_estimators=2000,metrics='default',subsample=0.8,ifmute='no',ifweight='no',ifrandom_split='no',ifsave='yes',savepath=r'E:/xuanxuan/xuanxuan_xgboost_classify_CN05_morev_sm2',device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e0119fa-ad59-42d2-9113-e0aae4001d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model,predicty,testy,r,p,weights=Auto_xgboost(vy,vx,test_size = 0.2,task_mode='binary_classify',if_best_mode='load',modelpath=r'E:/xuanxuan/xuanxuan_xgboost_classify_CN05_morev_sm2',ifcross_validation='no',k_fold_num=5,default_learning_rate=0.1,default_max_depth=50,default_num_leaves=100,default_max_bin=256,boosting_type='dart',n_estimators=0,metrics='default',subsample=0.8,ifmute='no',ifweight='no',ifrandom_split='no',ifsave='no',savepath=r'E:/xuanxuan/xuanxuan_xgboost_classify_CN05_morev_sm2',device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1fc5ac5-255a-4c65-9b0f-bb082d1b11a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "testy=testy.reshape(-int(CN05_PRE.shape[0]*0.1),CN05_PRE.shape[1],CN05_PRE.shape[2])\n",
    "predicty=predicty.reshape(-int(CN05_PRE.shape[0]*0.1),CN05_PRE.shape[1],CN05_PRE.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3b8eeac-cc89-42c4-8a23-4018276e66c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto_paint_self.create_nc(times[-int(testy.shape[0]):],lat,lon,None,testy,'time','lat','lon','testy','no',None,'yes','yes','yes','E:/xgboost_classify_testy.nc')\n",
    "Auto_paint_self.create_nc(times[-int(testy.shape[0]):],lat,lon,None,predicty,'time','lat','lon','testy','no',None,'yes','yes','yes','E:/xgboost_classify_predicty.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c154d11-3266-445d-a53c-20f7a9837d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
